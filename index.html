<!DOCTYPE HTML>
<!--
	Prologue by HTML5 UP
	html5up.net | @n33co
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>36-708</title>
		<meta charset="utf-8" />
	</head>
<body>
	<h1>36-708: The ABCDE of Statistical Methods in Machine Learning</h1>

<h2>Class location/time: Remote via Zoom (T & Th 2:20PM - 3:40PM)</h2>
	
<h3> Office hours: Aaditya Ramdas: (T 4-5pm), Ian Waudby-Smith: (W 1-2pm)</h3>

<b>Course details:</b><br>
<ul>
<li> <a href="course_information.html">Overview</a><br>
<li> <a href="Syllabus21.pdf">Syllabus</a><br><br>
</ul>

<b>Homework: </b><br>
<ul>
    <li> <a href="Homework/HW1.pdf">Homework 1</a>
    <li> <a href="Homework/HW2.pdf">Homework 2</a>
</ul>

<b>Scribes:</b><br>

<ul>
<li> <a href="https://docs.google.com/spreadsheets/d/1MH_WYKn_NHZVAWP3biDeGW7LL_0tEcJm91HI1qGcqpQ/edit?usp=sharing">Crowd-scribing sign-up sheet (access with a CMU account)</a><br>
<li> <a href="https://www.overleaf.com/read/jzhmrrfgfnkh">Crowd-scribed class notes (read-only; ask for edit link if in class)</a>
</ul>

<b>Lecture slides:</b><br>

<ul>
    <li> <a href="Lectures/feb16-class.pdf">Feb 16 - Conformal prediction</a>
</ul>

<br/>
<iframe width=1050px, height=700px, src="https://docs.google.com/spreadsheets/d/e/2PACX-1vT_qulaTsnP8yldIoj98g3EQHwilSaGbi9xou1Io2gOiNH0cI3TT8wnhdytD14SpHiIZ8eMDECYR6X8/pubhtml?gid=1992338820&amp;single=true&amp;widget=true&amp;headers=false"></iframe>

<br/>
<br/>

<b>Some textbooks:</b> <br>
<ul>
<li><a href="https://web.stanford.edu/~hastie/ElemStatLearn/">The Elements of Statistical Learning: Data Mining, Inference and Prediction.</a> Trevor Hastie, Robert Tibshirani, Jerome Friedman.<br>
<li><a href="http://faculty.marshall.usc.edu/gareth-james/ISL/">An Introduction to Statistical Learning: With Applications in R.</a> Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani.<br>
<li><a href="https://cs.nyu.edu/~mohri/mlbook/">Foundations of Machine Learning.</a> Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar.<br><br>
</ul>

<b>References to catch up on prerequisites:</b>
<ul>
  <li><a href=https://www.youtube.com/channel/UCu8Pv6IJsbQdGzRlZ5OipUg/videos>Videos of Larry Wasserman's 36-705 course</a><br>
  <li><a href="http://www.cs.cmu.edu/~zkolter/course/linalg/index.html">Linear algebra review</a>, videos by Zico Kolter<br>
  <li><a href="https://www.youtube.com/channel/UC7gOYDYEgXG1yIH_rc2LgOw/playlists">Real analysis, calculus, and more linear algebra</a>, videos by Aaditya Ramdas <br>
  <li><a href="prerequisite_topics.pdf">Convex optimization prequisites review</a> from Spring 2015 course, by Nicole Rafidi<br>
  <li>See also Appendix A of <a href="https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf">Boyd and Vandenberghe (2004) for general mathematical review</a><br><br>
</ul>
	  
<b>Potentially useful resources available online (not necessarily verified by the course staff):</b>
<ul>
  <li><a href="https://github.com/josephmisiti/awesome-machine-learning/blob/master/books.md">A list of machine learning books</a><br>
  <li><a href="http://ciml.info/">A course in machine learning</a><br>
   <li><a href="https://christophm.github.io/interpretable-ml-book/">Interpretable Machine Learning</a><br>
   <li><a href="https://fairmlbook.org/">Fairness and machine learning</a><br><br>
</ul>


Looking for the <a href="2020.html">2020 site? </a>

</body>

</html>
